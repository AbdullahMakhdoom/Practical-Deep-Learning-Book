{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-4/2-similarity-search-level-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/practicaldl/Practical-Deep-Learning-Book/blob/master/code/chapter-4/2-similarity-search-level-1.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "This code is part of [Chapter 4 - Building a Reverse Image Search Engine: Understanding Embeddings ](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch04.html).\n",
    "\n",
    "Note: In order to run this notebook on Google Colab you need to [follow these instructions](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#scrollTo=WzIRIt9d2huC) so that the local data such as the images are available in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search\n",
    "\n",
    "This notebook is the second among four of the follow along Jupyter notebook for chapter 4. Since we will be covering a lot of material in this notebook, we divided into three separate sections - level 1, level 2, and level 3.\n",
    "\n",
    "In level 1, we write an indexer to index features and search for most similar features using various nearest neighbor algorithms, and explore various methods of visualizing plots.\n",
    "\n",
    "In level 2, we benchmark the algorithms based on the time it takes to index images and locate the most similar image based on its features using the Caltech-101 dataset. We also experiment with t-SNE and PCA.\n",
    "\n",
    "In level 3, we calculate the accuracies of the features obtained from the pretrained and finetuned models. The finetuning here follows chapter 2.\n",
    "\n",
    "## Level 1\n",
    "\n",
    "Here we visualize some query images represented by their standard features with their nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the files we wrote to disk in our previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pickle.load(open('./data/filenames-caltech101.pickle', 'rb'))\n",
    "feature_list = pickle.load(open('data/features-caltech101-resnet.pickle',\n",
    "                                'rb'))\n",
    "class_ids = pickle.load(open('./data/class_ids-caltech101.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(filenames)\n",
    "num_features_per_image = len(feature_list[0])\n",
    "print(\"Number of images = \", num_images)\n",
    "print(\"Number of features per image = \", num_features_per_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use python's machine learning library 'scikit-learn' for finding Nearest Neighbors.\n",
    "\n",
    "To install within the `virtualenv` use: \n",
    "\n",
    "`pip3 install sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5,\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = 75\n",
    "distances, indices = neighbors.kneighbors([feature_list[random_index]])\n",
    "plt.imshow(mpimg.imread(filenames[choice_index]), interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][0]]), interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, isn’t that a duplicate? Actually, the nearest index will be the image itself because that is what is being queried.\n",
    "\n",
    "Let’s plot the real first nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][1]]), interpolation='lanczos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(distances[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the distance of the query image to the first closest image is zero, again showing that the closest image to the query image is the same image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Now, lets start our experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the classname\n",
    "def classname(str):\n",
    "    return str.split('/')[-2]\n",
    "\n",
    "\n",
    "# Helper function to get the classname and filename\n",
    "def classname_filename(str):\n",
    "    return str.split('/')[-2] + '/' + str.split('/')[-1]\n",
    "\n",
    "\n",
    "# Helper functions to plot the nearest images given a query image\n",
    "def plot_images(filenames, distances):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 4\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Query Image\\n\" + classname_filename(filenames[i]))\n",
    "        else:\n",
    "            ax.set_title(\"Similar Image\\n\" + classname_filename(filenames[i]) +\n",
    "                         \"\\nDistance: \" +\n",
    "                         str(float(\"{0:.2f}\".format(distances[i]))))\n",
    "        plt.imshow(image)\n",
    "        # To save the plot in a high definition format i.e. PDF, uncomment the following line:\n",
    "        #plt.savefig('results/' + str(random.randint(0,10000))+'.pdf', format='pdf', dpi=1000)\n",
    "        # We will use this line repeatedly in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    random_image_index = random.randint(0, num_images)\n",
    "    distances, indices = neighbors.kneighbors(\n",
    "        [feature_list[random_image_index]])\n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "    plot_images(similar_image_paths, distances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get a sense of the similarity values by looking at distance stats over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=len(feature_list),\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list)\n",
    "distances, indices = neighbors.kneighbors(feature_list)\n",
    "\n",
    "# Calculating some stats\n",
    "print(\"Median distance between all photos: \", np.median(distances))\n",
    "print(\"Max distance between all photos: \", np.max(distances))\n",
    "print(\"Median distance among most similar photos: \",\n",
    "      np.median(distances[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the amount of data you want to run the experiments on. Here we are selecting the entire dataset. To enable quicker run times you may want to select a portion of the dataset to experiment on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_list[:]\n",
    "selected_class_ids = class_ids[:]\n",
    "selected_filenames = filenames[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, for ease of illustration and speed we can simply pick a thousand image samples to plot the t-SNE results. \n",
    "\n",
    "```\n",
    "selected_features = feature_list[7000:8000]\n",
    "selected_class_ids = class_ids[7000:8000]\n",
    "selected_filenames = filenames[7000:8000]\n",
    "```\n",
    "Note: It is important to run the entire dataset, if you wish to benchmark the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-SNE algorithm is useful for visualizing high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# You can play with these values and see how the results change\n",
    "n_components = 2\n",
    "verbose = 1\n",
    "perplexity = 30\n",
    "n_iter = 1000\n",
    "metric = 'euclidean'\n",
    "\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=n_components,\n",
    "                    verbose=verbose,\n",
    "                    perplexity=perplexity,\n",
    "                    n_iter=n_iter,\n",
    "                    metric=metric).fit_transform(selected_features)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a scatter plot from the generated t-SNE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color_map = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:, 0],\n",
    "                           tsne_results[:, 1],\n",
    "                           c=selected_class_ids,\n",
    "                           cmap=color_map)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()\n",
    "# To save the plot in a high definition format i.e. PDF, uncomment the following line:\n",
    "#plt.savefig('results/' + str(ADD_NAME_HERE)+'.pdf', format='pdf', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a helper function to plot images in 2D for t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "\n",
    "\n",
    "def plot_images_in_2d(x, y, image_paths, axis=None, zoom=1):\n",
    "    if axis is None:\n",
    "        axis = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    for x0, y0, image_path in zip(x, y, image_paths):\n",
    "        image = Image.open(image_path)\n",
    "        image.thumbnail((100, 100), Image.ANTIALIAS)\n",
    "        img = OffsetImage(image, zoom=zoom)\n",
    "        anno_box = AnnotationBbox(img, (x0, y0),\n",
    "                                  xycoords='data',\n",
    "                                  frameon=False)\n",
    "        axis.add_artist(anno_box)\n",
    "    axis.update_datalim(np.column_stack([x, y]))\n",
    "    axis.autoscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a helper function to render a t-SNE plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tsne(x, y, selected_filenames):\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.set_size_inches(22, 22, forward=True)\n",
    "    plot_images_in_2d(x, y, selected_filenames, zoom=0.3, axis=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Visualize the patterns in the images using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_tsne(tsne_results[:, 0], tsne_results[:, 1], selected_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show_tsne` function piles images one on top of each other, making it harder to discern the patterns as the density of images is high. To help visualize the patterns better, we write another helper function `tsne_to_grid_plotter_manual` that spaces the images evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_to_grid_plotter_manual(x, y, selected_filenames):\n",
    "    S = 2000\n",
    "    s = 100\n",
    "    x = (x - min(x)) / (max(x) - min(x))\n",
    "    y = (y - min(y)) / (max(y) - min(y))\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    filename_plot = []\n",
    "    x_y_dict = {}\n",
    "    for i, image_path in enumerate(selected_filenames):\n",
    "        a = np.ceil(x[i] * (S - s))\n",
    "        b = np.ceil(y[i] * (S - s))\n",
    "        a = int(a - np.mod(a, s))\n",
    "        b = int(b - np.mod(b, s))\n",
    "        if str(a) + \"|\" + str(b) in x_y_dict:\n",
    "            continue\n",
    "        x_y_dict[str(a) + \"|\" + str(b)] = 1\n",
    "        x_values.append(a)\n",
    "        y_values.append(b)\n",
    "        filename_plot.append(image_path)\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.set_size_inches(22, 22, forward=True)\n",
    "    plot_images_in_2d(x_values, y_values, filename_plot, zoom=.58, axis=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne_to_grid_plotter_manual(tsne_results[:, 0], tsne_results[:, 1],\n",
    "                            selected_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "We will perform [Principal Component Analysis (PCA)](https://asaip.psu.edu/submitted-papers/2013/liii.-on-lines-and-planes-of-closest-fit-to-systems-of-points-in-space) over the features using `100` feature dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_dimensions = 100\n",
    "pca = PCA(n_components=num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5,\n",
    "                             algorithm='brute',\n",
    "                             metric='euclidean').fit(feature_list_compressed)\n",
    "distances, indices = neighbors.kneighbors([feature_list_compressed[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some query images with their nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    random_image_index = random.randint(0, num_images)\n",
    "    distances, indices = neighbors.kneighbors(\n",
    "        [feature_list_compressed[random_image_index]])\n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "    plot_images(similar_image_paths, distances[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for speed we pick a few thousand image samples. (You can choose to benchmark the entire dataset by removing the upper limit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_list_compressed[:4000]\n",
    "selected_class_ids = class_ids[:4000]\n",
    "selected_filenames = filenames[:4000]\n",
    "\n",
    "time_start = time.time()\n",
    "tsne_results = TSNE(n_components=2, verbose=1,\n",
    "                    metric='euclidean').fit_transform(selected_features)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a scatter plot from the generated t-SNE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:, 0],\n",
    "                           tsne_results[:, 1],\n",
    "                           c=selected_class_ids,\n",
    "                           cmap=color_map)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the patterns in the images using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_tsne(tsne_results[:, 0], tsne_results[:, 1], selected_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsne_to_grid_plotter_manual(tsne_results[:, 0], tsne_results[:, 1],\n",
    "                            selected_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
